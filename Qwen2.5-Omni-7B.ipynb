{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb475c75-d5f3-420d-b801-de8f79e7ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.52.3\n",
      "  Using cached transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting safetensors\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting filelock (from transformers==4.52.3)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.52.3)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.3) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.3) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.52.3)\n",
      "  Using cached regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.3) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.52.3)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.3) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.3) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.3) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.3)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch>=2.0.0->accelerate)\n",
      "  Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.52.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.52.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.52.3) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.52.3) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Using cached transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, triton, sympy, sentencepiece, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-xet, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, accelerate\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.0\n",
      "    Uninstalling sympy-1.13.0:\n",
      "      Successfully uninstalled sympy-1.13.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.3.101\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.3.101:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.3.101\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.4.107\n",
      "    Uninstalling nvidia-curand-cu12-10.3.4.107:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.4.107\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.3.101\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.3.101:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.3.101\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.3.107\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.3.107:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.3.107\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.3.101\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.3.101:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.3.101\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.3.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.3.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.3.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.2.0.103\n",
      "    Uninstalling nvidia-cusparse-cu12-12.2.0.103:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.2.0.103\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.12.1\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.12.1:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.12.1\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.7.29\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.7.29:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.7.29\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.5.4.101\n",
      "    Uninstalling nvidia-cusolver-cu12-11.5.4.101:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.5.4.101\n",
      "Successfully installed accelerate-1.12.0 filelock-3.20.0 hf-xet-1.2.0 huggingface-hub-0.36.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 regex-2025.11.3 safetensors-0.7.0 sentencepiece-0.2.1 sympy-1.14.0 tokenizers-0.21.4 torch-2.9.1 transformers-4.52.3 triton-3.5.1\n",
      "Collecting qwen-omni-utils[decord]\n",
      "  Using cached qwen_omni_utils-0.0.8-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting av (from qwen-omni-utils[decord])\n",
      "  Using cached av-16.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting librosa (from qwen-omni-utils[decord])\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from qwen-omni-utils[decord]) (24.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from qwen-omni-utils[decord]) (10.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from qwen-omni-utils[decord]) (2.32.3)\n",
      "Collecting decord (from qwen-omni-utils[decord])\n",
      "  Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from decord->qwen-omni-utils[decord]) (1.26.4)\n",
      "Collecting audioread>=2.1.9 (from librosa->qwen-omni-utils[decord])\n",
      "  Using cached audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils[decord]) (0.60.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils[decord]) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils[decord]) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils[decord]) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils[decord]) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa->qwen-omni-utils[decord])\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa->qwen-omni-utils[decord])\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->qwen-omni-utils[decord])\n",
      "  Using cached soxr-1.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils[decord]) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils[decord]) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils[decord]) (1.0.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->qwen-omni-utils[decord]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->qwen-omni-utils[decord]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->qwen-omni-utils[decord]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->qwen-omni-utils[decord]) (2024.7.4)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.0->librosa->qwen-omni-utils[decord]) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa->qwen-omni-utils[decord]) (4.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa->qwen-omni-utils[decord]) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa->qwen-omni-utils[decord]) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->qwen-omni-utils[decord]) (2.22)\n",
      "Using cached av-16.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (40.2 MB)\n",
      "Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached qwen_omni_utils-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Using cached audioread-3.1.0-py3-none-any.whl (23 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "Using cached soxr-1.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (242 kB)\n",
      "Installing collected packages: soxr, decord, av, audioread, soundfile, pooch, librosa, qwen-omni-utils\n",
      "Successfully installed audioread-3.1.0 av-16.0.1 decord-0.6.0 librosa-0.11.0 pooch-1.8.2 qwen-omni-utils-0.0.8 soundfile-0.13.1 soxr-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers==4.52.3\" accelerate sentencepiece safetensors\n",
    "!pip install qwen-omni-utils[decord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15db5db8-9831-4b43-84dd-147eed078fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Qwen2.5-Omni' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/QwenLM/Qwen2.5-Omni.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca00f9a-8356-4d07-ab14-b5032eff8c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers@v4.51.3-Qwen2.5-Omni-preview\n",
      "  Cloning https://github.com/huggingface/transformers (to revision v4.51.3-Qwen2.5-Omni-preview) to /tmp/pip-req-build-p5dizy5i\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-p5dizy5i\n",
      "  Running command git checkout -q f551466201fb4089d6df9dc55d80f0edbd149d85\n",
      "  Resolved https://github.com/huggingface/transformers to commit f551466201fb4089d6df9dc55d80f0edbd149d85\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.52.0.dev0) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.52.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.52.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.52.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.52.0.dev0) (2024.7.4)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.52.0.dev0-py3-none-any.whl size=11252795 sha256=0031b99b613ec3efcc76e50ed55e270570b9fce42596823ec687db0a048a6007\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-x5wjrf18/wheels/9d/a4/d1/9bf234fcabd7d01ba2e55b65f426d7b52be31a63631cd091eb\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.52.3\n",
      "    Uninstalling transformers-4.52.3:\n",
      "      Successfully uninstalled transformers-4.52.3\n",
      "Successfully installed transformers-4.52.0.dev0\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"git+https://github.com/huggingface/transformers@v4.51.3-Qwen2.5-Omni-preview\"\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce1d3858-7c2e-4d07-beee-f4bbb7b57da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a986df512140fea962bfd4f242d55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processor loaded.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Qwen2_5OmniForConditionalGeneration, AutoProcessor\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device() if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-Omni-7B\"\n",
    "\n",
    "model = Qwen2_5OmniForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,   # good for L40\n",
    "    device_map=\"auto\",            # let HF spread it on your GPU\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "print(\"Model and processor loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f203c57b-a7ed-4cfe-b6bc-53aeaa97e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of inputs: <class 'transformers.feature_extraction_utils.BatchFeature'>\n",
      "\n",
      "Model reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "Say hello in one short sentence.\n",
      "assistant\n",
      "Hello. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# EXACT default system prompt (so we stop seeing that warning)\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\"\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Say hello in one short sentence.\"\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Batch with ONE conversation\n",
    "conversations = [conversation]\n",
    "\n",
    "# This follows the Hugging Face Qwen2.5-Omni docs\n",
    "inputs = processor.apply_chat_template(\n",
    "    conversations,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,      # ðŸ‘ˆ important: returns a dict / BatchEncoding, not a tensor\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ").to(model.device)\n",
    "\n",
    "print(\"Type of inputs:\", type(inputs))\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_ids = model.generate(\n",
    "        **inputs,\n",
    "        return_audio=False,    # text only\n",
    "        max_new_tokens=64,\n",
    "    )\n",
    "\n",
    "# Decode the whole sequence (no manual slicing to keep it simple)\n",
    "texts = processor.batch_decode(\n",
    "    text_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False,\n",
    ")\n",
    "\n",
    "print(\"\\nModel reply:\\n\", texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1507808d-d07a-4824-8b77-95e2ba265fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qwen-omni-utils in /opt/conda/lib/python3.11/site-packages (0.0.8)\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.11/site-packages (0.13.1)\n",
      "Requirement already satisfied: av in /opt/conda/lib/python3.11/site-packages (from qwen-omni-utils) (16.0.1)\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.11/site-packages (from qwen-omni-utils) (0.11.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from qwen-omni-utils) (24.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from qwen-omni-utils) (10.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from qwen-omni-utils) (2.32.3)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from soundfile) (1.26.4)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (0.60.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.11/site-packages (from librosa->qwen-omni-utils) (1.0.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->qwen-omni-utils) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->qwen-omni-utils) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->qwen-omni-utils) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->qwen-omni-utils) (2024.7.4)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.0->librosa->qwen-omni-utils) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa->qwen-omni-utils) (4.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa->qwen-omni-utils) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U qwen-omni-utils soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca9f505-7b65-41e8-8a16-f1aedfc59e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.9.1 in /opt/conda/lib/python3.11/site-packages (from torchvision) (2.9.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.9.1->torchvision) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.9.1->torchvision) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "import time\n",
    "import torchvision\n",
    "import soundfile as sf\n",
    "from qwen_omni_utils import process_mm_info\n",
    "\n",
    "# EXACT system prompt Qwen expects for audio\n",
    "QWEN_SYSTEM_PROMPT = (\n",
    "    \"You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, \"\n",
    "    \"capable of perceiving auditory and visual inputs, as well as generating text and speech.\"\n",
    ")\n",
    "\n",
    "def run_qwen_audio_turn(audio_path, speaker=\"Chelsie\", save_path=\"qwen_reply.wav\"):\n",
    "    \"\"\"\n",
    "    audio_path: path to your input WAV file (one of your prompts)\n",
    "    speaker: \"Chelsie\" or \"Ethan\" (built-in voices)\n",
    "    save_path: where to save Qwen's spoken reply\n",
    "    \"\"\"\n",
    "    # 1) Build conversation with required system prompt + user audio\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": QWEN_SYSTEM_PROMPT}\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"audio\", \"audio\": audio_path},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    conversations = [conversation]\n",
    "    USE_AUDIO_IN_VIDEO = False  # we are not using video here\n",
    "\n",
    "    # 2) Prepare text template (not tokenized, Qwen will handle multimodal tokens)\n",
    "    text = processor.apply_chat_template(\n",
    "        conversations,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=False,\n",
    "    )\n",
    "\n",
    "    # 3) Extract multimodal info (audio paths -> tensors)\n",
    "    audios, images, videos = process_mm_info(\n",
    "        conversations,\n",
    "        use_audio_in_video=USE_AUDIO_IN_VIDEO,\n",
    "    )\n",
    "\n",
    "    # 4) Pack everything into model inputs\n",
    "    inputs = processor(\n",
    "        text=text,\n",
    "        audio=audios,\n",
    "        images=images,\n",
    "        videos=videos,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        use_audio_in_video=USE_AUDIO_IN_VIDEO,\n",
    "    )\n",
    "    inputs = inputs.to(model.device).to(model.dtype)\n",
    "\n",
    "    # 5) Generate text + audio and time it for latency\n",
    "    t_start = time.time()\n",
    "    text_ids, audio = model.generate(\n",
    "        **inputs,\n",
    "        use_audio_in_video=USE_AUDIO_IN_VIDEO,\n",
    "        speaker=speaker,      # \"Chelsie\" or \"Ethan\"\n",
    "        max_new_tokens=128,\n",
    "        return_audio=True,\n",
    "    )\n",
    "    t_end = time.time()\n",
    "    latency = t_end - t_start\n",
    "\n",
    "    # 6) Decode text\n",
    "    reply_text = processor.batch_decode(\n",
    "        text_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False,\n",
    "    )[0]\n",
    "\n",
    "    print(\"Qwen text reply:\\n\", reply_text)\n",
    "    print(f\"\\nEnd-to-end latency: {latency:.3f} seconds\")\n",
    "\n",
    "    # 7) Save reply audio for MOS / naturalness rating\n",
    "    audio_np = audio.reshape(-1).detach().cpu().numpy()\n",
    "    sf.write(save_path, audio_np, samplerate=24000)\n",
    "    print(\"Saved reply audio to:\", save_path)\n",
    "\n",
    "    return latency, reply_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "442ad695-3e6c-449d-8f0f-ce4062ebca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q gTTS pydub\n",
    "\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca8882d4-5004-4e99-a2ff-5997b9976b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… prosody.wav created!\n"
     ]
    }
   ],
   "source": [
    "# Generate TTS audio and save as mp3\n",
    "tts = gTTS(\"Say this sentence in a angry tone: â€˜Are you mad?\", lang=\"en\")\n",
    "tts.save(\"prosody.mp3\")\n",
    "\n",
    "# Convert mp3 to wav\n",
    "sound = AudioSegment.from_mp3(\"prosody.mp3\")\n",
    "sound.export(\"prosody.wav\", format=\"wav\")\n",
    "\n",
    "print(\"âœ… prosody.wav created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c95d65-cc4a-4c98-87b9-a5ccab22c97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Qwen on prosody.wav (Prompt 1) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt_files = [\n",
    "    \"prosody.wav\"\n",
    "]\n",
    "\n",
    "latencies = []\n",
    "\n",
    "for i, wav in enumerate(prompt_files, start=1):\n",
    "    print(f\"\\n=== Running Qwen on {wav} (Prompt {i}) ===\")\n",
    "    lat, _ = run_qwen_audio_turn(\n",
    "        wav,\n",
    "        speaker=\"Chelsie\",\n",
    "        save_path=f\"qwen_reply_prompt{i}.wav\",\n",
    "    )\n",
    "    latencies.append(lat)\n",
    "\n",
    "print(\"\\nAll latencies:\", latencies)\n",
    "print(\"Average latency:\", sum(latencies) / len(latencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd893be3-344c-4116-8718-4b1aa6f9851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Qwen on p1.wav (Prompt 1) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "End-to-end latency: 3.629 seconds\n",
      "Saved reply audio to: qwen_reply_prompt1.wav\n",
      "\n",
      "=== Running Qwen on p2.wav (Prompt 2) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Well, 2 plus 2 is 4. It's a simple math fact. If you have any other other math questions or other anything else you want to talk about, feel free to let me know.\n",
      "\n",
      "End-to-end latency: 15.122 seconds\n",
      "Saved reply audio to: qwen_reply_prompt2.wav\n",
      "\n",
      "=== Running Qwen on p3.wav (Prompt 3) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Hello, I am Qwen, a large-scale language model developed by Alibaba Cloud. How can I assist you?\n",
      "\n",
      "End-to-end latency: 8.150 seconds\n",
      "Saved reply audio to: qwen_reply_prompt3.wav\n",
      "\n",
      "=== Running Qwen on p4.wav (Prompt 4) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Why was the math book look so sad? Because it had too many problems. Hehe. So, do you want to hear more jokes?\n",
      "\n",
      "End-to-end latency: 9.287 seconds\n",
      "Saved reply audio to: qwen_reply_prompt4.wav\n",
      "\n",
      "=== Running Qwen on p5.wav (Prompt 5) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Well, a robot is a machine that can perform tasks automatically, often with some level of intelligence or programmability. So, what do you think about robots? Do you have any specific questions about them?\n",
      "\n",
      "End-to-end latency: 16.575 seconds\n",
      "Saved reply audio to: qwen_reply_prompt5.wav\n",
      "\n",
      "=== Running Qwen on p6.wav (Prompt 6) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Well, you know, there are a few reasons. One is that dreams can be a way for your brain to process information from the day. It's like it's sorting through all all the things that happened. Another reason could be that dreams might be related to your emotions. If you're stressed or happy, your dreams could be reflecting that. And some scientists think that dreams could also be a way for your brain to practice things, like if you dream about running, it could be a way to practice your running skills. But it's still not completely clear. So, what do you think about dreams? Do you have any interesting dreams to share?\n",
      "\n",
      "End-to-end latency: 67.244 seconds\n",
      "Saved reply audio to: qwen_reply_prompt6.wav\n",
      "\n",
      "=== Running Qwen on p7.wav (Prompt 7) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Well, during photosynthesis, plants use sunlight, water, and carbon dioxide. The sunlight is absorbed by the chlorophyll in the leaves. Then, through a series of chemical reactions, the plant converts these into glucose, which is food for the plant, and oxygen, which is released into the air.If you want to know more about photosynthesis, like what happens if the sunlight isn't enough, just let me know.\n",
      "\n",
      "End-to-end latency: 37.048 seconds\n",
      "Saved reply audio to: qwen_reply_prompt7.wav\n",
      "\n",
      "=== Running Qwen on p8.wav (Prompt 8) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Well, first off, wind energy is renewable. Youåœé¡¿ï¼Œå—¯ï¼Œå°±æ˜¯è¯´å®ƒä¸ä¼šåƒçŸ³æ²¹ï¼Œç…¤ç‚­é‚£æ ·ç”¨å®Œå°±æ²¡äº†ã€‚ç¬¬äºŒå‘¢ï¼Œå®ƒå¯¹çŽ¯å¢ƒå¾ˆå‹å¥½ã€‚é£Žèƒ½å‘ç”µä¸ä¼šäº§ç”Ÿæ¸©å®¤æ°”ä½“æŽ’æ”¾ï¼ŒåƒäºŒæ°§åŒ–ç¢³å•¥çš„ï¼Œå¯¹ä¿æŠ¤çŽ¯å¢ƒå¾ˆæœ‰å¸®åŠ©ã€‚è¿˜æœ‰å•Šï¼Œé£Žèƒ½å‘ç”µæˆæœ¬åœ¨ä¸æ–­é™ä½Žã€‚éšç€æŠ€æœ¯çš„å‘å±•ï¼Œå»ºé£ŽåŠ›å‘ç”µåœºçš„æˆæœ¬è¶Šæ¥è¶Šä½Žäº†ã€‚ä½ è¦æ˜¯è¿˜æœ‰å•¥æƒ³çŸ¥é“çš„ï¼Œå°½ç®¡å†é—®å“ˆã€‚\n",
      "\n",
      "End-to-end latency: 51.917 seconds\n",
      "Saved reply audio to: qwen_reply_prompt8.wav\n",
      "\n",
      "=== Running Qwen on p9.wav (Prompt 9) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Well, it's about a human named Jake who goes to a planet called Pandora. He's there to collect resources but ends up befriending the Na'vi, the native people there. He learns about their culture and becomes a part of it. In the end, he has to fight to protect the Na'vi and their home planet. So, what do you think about that? Do you have any other other questions about the movie?\n",
      "\n",
      "End-to-end latency: 29.536 seconds\n",
      "Saved reply audio to: qwen_reply_prompt9.wav\n",
      "\n",
      "=== Running Qwen on p10.wav (Prompt 10) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:8292 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen text reply:\n",
      " system\n",
      "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\n",
      "user\n",
      "\n",
      "assistant\n",
      "Well, you know, machine learning is like teaching a computer to learn from data. It has a bunch of data, like pictures or numbers. The computer looks at this data and finds patterns. For example, if a bunch of pictures of cats and dogs. It can learn what makes a picture a cat or a dog. Then, when it sees a new picture, it can figure out if it's a cat or a dog based on what it learned before. It doesn't need to be told exactly what to do, it just figures it out from the data. So, it's kind of like a computer learning to play a game by watching other play it over times.If you want to know more about it, like how it actually does the learning part, just let me know.\n",
      "\n",
      "End-to-end latency: 70.639 seconds\n",
      "Saved reply audio to: qwen_reply_prompt10.wav\n",
      "\n",
      "All latencies: [3.629286289215088, 15.122192859649658, 8.150470972061157, 9.286615371704102, 16.57548213005066, 67.24404311180115, 37.04815459251404, 51.916807651519775, 29.536121129989624, 70.63876271247864]\n",
      "Average latency: 30.914793682098388\n"
     ]
    }
   ],
   "source": [
    "prompt_files = [\n",
    "    \"p1.wav\",\n",
    "    \"p2.wav\",\n",
    "    \"p3.wav\",\n",
    "    \"p4.wav\",\n",
    "    \"p5.wav\",\n",
    "    \"p6.wav\",\n",
    "    \"p7.wav\",\n",
    "    \"p8.wav\",\n",
    "    \"p9.wav\",\n",
    "    \"p10.wav\",\n",
    "]\n",
    "\n",
    "latencies = []\n",
    "\n",
    "for i, wav in enumerate(prompt_files, start=1):\n",
    "    print(f\"\\n=== Running Qwen on {wav} (Prompt {i}) ===\")\n",
    "    lat, _ = run_qwen_audio_turn(\n",
    "        wav,\n",
    "        speaker=\"Chelsie\",\n",
    "        save_path=f\"qwen_reply_prompt{i}.wav\",\n",
    "    )\n",
    "    latencies.append(lat)\n",
    "\n",
    "print(\"\\nAll latencies:\", latencies)\n",
    "print(\"Average latency:\", sum(latencies) / len(latencies))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
